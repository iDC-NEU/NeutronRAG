import functools
import json
import os
import random
import re
import sys
import time
import traceback
import uuid
from datetime import datetime, timezone

from typing import Union, Optional

from dotenv import load_dotenv
from flask import Flask, request, jsonify, render_template, session, redirect, url_for, Response
from flask_cors import CORS
from flask_sqlalchemy import SQLAlchemy
from watchdog.events import FileSystemEventHandler
from watchdog.observers import Observer
from werkzeug.security import generate_password_hash, check_password_hash
from zhipuai import ZhipuAI

#from config.config import Config
from db_setup import db
from models import User, ChatSession, ChatMessage
from database.mysql.mysql import MySQLManager
#from user import User

mysql = MySQLManager(database="chat")

current_dir = os.getcwd()

# è·å–å½“å‰å·¥ä½œç›®å½•çš„ä¸Šçº§ç›®å½•
parent_dir = os.path.dirname(current_dir)

# æ‹¼æ¥å‡º 'backend' æ–‡ä»¶å¤¹çš„è·¯å¾„
backend_dir = os.path.join(parent_dir, 'backend')

# å°† 'backend' ç›®å½•æ·»åŠ åˆ° sys.path ä¸­
sys.path.append(backend_dir)
from  llmragenv.llmrag_env import LLMRAGEnv
from llmragenv.demo_chat import *
from evaluator import simulate
from llmragenv.demo_chat import Demo_chat
import threading
import traceback

# --- RAG æ ¸å¿ƒé€»è¾‘å¯¼å…¥ ---
RAG_CORE_LOADED = False # <--- æ£€æŸ¥ï¼ï¼æ˜¯å¦åœ¨ try ä¹‹å‰æœ‰è¿™è¡Œåˆå§‹åŒ–ï¼Ÿ
try:
    from llmragenv.demo_chat import Demo_chat
    RAG_CORE_LOADED = True # æˆåŠŸå¯¼å…¥åˆ™è®¾ä¸º True
except ImportError as e:
    print(f"è­¦å‘Šï¼šæ— æ³•å¯¼å…¥ RAG æ ¸å¿ƒé€»è¾‘ 'llmragenv.demo_chat'ï¼š{e}")
    # æ­¤å¤„ RAG_CORE_LOADED ä¿æŒä¸º False
    Demo_chat = None
from evaluator import simulate

################å­—å…¸å­˜å…¥çš„mysqlæ˜¯TEXTè¿™ä¸ªåœ¨è¿˜åŸå›æ¥#####################
def parse_json_field(value):
    try:
        return json.loads(value) if value else None
    except Exception as e:
        print(f"âš ï¸ è§£æå¤±è´¥: {e}")
        return None

# =========================================
# åˆå§‹åŒ–ä¸é…ç½®
# =========================================
load_dotenv() # åŠ è½½ .env æ–‡ä»¶

app = Flask(__name__, instance_relative_config=True) # åˆå§‹åŒ– Flask åº”ç”¨

# --- åº”ç”¨é…ç½® ---
# å¿…é¡»è®¾ç½®å¼ºå¯†é’¥ç”¨äº Session å®‰å…¨
app.config['SECRET_KEY'] = os.environ.get('FLASK_SECRET_KEY', 'dev-insecure-key-change-me')
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False

# æ•°æ®åº“ URI é…ç½® (ä¾èµ–ç¯å¢ƒå˜é‡)
db_uri = os.environ.get('DATABASE_URL', None)
if db_uri is None:
    print("é”™è¯¯ï¼šå¯åŠ¨å¿…éœ€çš„ DATABASE_URL ç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼è¯·è®¾ç½®æŒ‡å‘ MySQL çš„è¿æ¥å­—ç¬¦ä¸²ã€‚")
    app.config['SQLALCHEMY_DATABASE_URI'] = None
else:
     app.config['SQLALCHEMY_DATABASE_URI'] = db_uri

# --- åˆå§‹åŒ–æ•°æ®åº“ ---
# ç›´æ¥åˆå§‹åŒ–ï¼Œå¦‚æœ URI æ— æ•ˆæˆ– db æœªå®šä¹‰ï¼Œä¼šåœ¨æ‰§è¡Œæ—¶å‡ºé”™
try:
    db.init_app(app)
    print("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆã€‚")
    DB_INIT_SUCCESS = True
except Exception as init_db_err:
     print(f"é”™è¯¯ï¼šåˆå§‹åŒ–æ•°æ®åº“å¤±è´¥ï¼š{init_db_err}")
     DB_INIT_SUCCESS = False # æ ‡è®°æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥

# --- å…¨å±€ RAG æ¨¡å‹å®ä¾‹ (æ‰€æœ‰ç”¨æˆ·å…±äº«) ---
current_model: Union[Demo_chat, None] = None # ç±»å‹æç¤º
current_model_dataset_info = {}

# =========================================
# è£…é¥°å™¨
# =========================================
def login_required(f):
    """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ç™»å½•ï¼Œæœªç™»å½•åˆ™é‡å®šå‘æˆ–è¿”å›401ã€‚"""
    @functools.wraps(f)
    def decorated_function(*args, **kwargs):
        if 'user_id' not in session:
            if request.accept_mimetypes.accept_json and not request.accept_mimetypes.accept_html:
                return jsonify({"error": "éœ€è¦è®¤è¯", "login_required": True}), 401
            return redirect(url_for('login_page', next=request.url))
        return f(*args, **kwargs)
    return decorated_function
    
# --- åŸå§‹æ–‡ä»¶è·¯å¾„å’Œå‡½æ•° ---

VECTOR_FILE_PATH = '/home/lipz/NeutronRAG/NeutronRAG/backend/evaluator/rgb/vectorrag/analysis_retrieval___top5_2024-11-26_21-32-23.json'
GRAPH_FILE_PATH = '/home/lipz/NeutronRAG/NeutronRAG/backend/evaluator/rgb/graphrag/analysis_retrieval_merged.json'
EVIDENCE_FILE_PATH = "/home/lipz/NeutronRAG/NeutronRAG/backend/evaluator/rgb_evidence.json"

##åŠ è½½å“åº”çš„idæ•°æ®
def load_and_filter_data(file_path, item_id):
    # æ³¨æ„: æ­¤å‡½æ•°æœŸæœ› item_id æ˜¯æ•´æ•°ï¼Œç”¨äºæŸ¥æ‰¾é™æ€æ–‡ä»¶ã€‚
    # å¦‚æœå‰ç«¯åœ¨ API æ¨¡å¼ä¸‹ä¼ é€’ UUIDï¼Œè¿™é‡Œä¼šæŸ¥æ‰¾å¤±è´¥ã€‚
    try:
        item_id_int = int(item_id)
    except (ValueError, TypeError):
         # print(f"Warning: load_and_filter_data: Could not convert item_id '{item_id}' to integer.") # å¯é€‰çš„è°ƒè¯•ä¿¡æ¯
         return None # æ— æ³•ç”¨éæ•´æ•°IDåœ¨æ­¤å‡½æ•°ä¸­æŸ¥æ‰¾

    try:
            data = load_all_items(file_path)
            # é€šè¿‡ item_id æŸ¥æ‰¾å¯¹åº”çš„å…ƒç´ 
            filtered_data = next((item for item in data if item.get('id') == item_id_int), None)
            return filtered_data
    except FileNotFoundError:
        print(f"File {file_path} not found.")
        return None
    except json.JSONDecodeError:
        print(f"Error decoding JSON from {file_path}.")
        return None

#####æŒ‰è¡Œé€ä¸ªè¯»å–
def load_all_items(file_path):
    items = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                items.append(json.loads(line.strip()))
            except json.JSONDecodeError:
                continue
    return items

def find_right_arrow(s):
    """
    æŸ¥æ‰¾å­—ç¬¦ä¸²ä¸­æ‰€æœ‰ "->" çš„èµ·å§‹ä½ç½®
    """
    right_arrow_positions = []
    i = 0
    while i < len(s) - 1:  # ç¡®ä¿ä¸ä¼šè¶Šç•Œ
        if s[i:i+2] == "->":
            right_arrow_positions.append(i)
            i += 2  # è·³è¿‡è¿™ä¸¤ä¸ªå­—ç¬¦ï¼Œé¿å…é‡å¤æŸ¥æ‰¾
        else:
            i += 1
    return right_arrow_positions

def find_left_arrow(s):
    """
    æŸ¥æ‰¾å­—ç¬¦ä¸²ä¸­æ‰€æœ‰ "<-" çš„èµ·å§‹ä½ç½®
    """
    left_arrow_positions = []
    i = 0
    while i < len(s) - 1:  # ç¡®ä¿ä¸ä¼šè¶Šç•Œ
        if s[i:i+2] == "<-":
            left_arrow_positions.append(i)
            i += 2  # è·³è¿‡è¿™ä¸¤ä¸ªå­—ç¬¦ï¼Œé¿å…é‡å¤æŸ¥æ‰¾
        else:
            i += 1
    return left_arrow_positions

#è·å–æ‰€æœ‰çš„-çš„ä½ç½®ï¼Œä½†å®ƒä¸ä¸€å®šæ˜¯å…³ç³»çš„åˆ†éš”ç¬¦
def get_all_dash(s):
    dash_positions = []
    i = 0
    while i < len(s):
        if s[i] == "-":
            # æ£€æŸ¥å½“å‰ä½ç½®æ˜¯å¦å±äºç®­å¤´çš„ä¸€éƒ¨åˆ†
            if i > 0 and ((s[i:i+2] == "->") or (s[i-1:i+1] == "<-")):
                i += 1  # è·³è¿‡æ•´ä¸ªç®­å¤´ï¼ˆä¸¤ä¸ªå­—ç¬¦ï¼‰ï¼Œé¿å…è¯¯åˆ¤ "-" ä¸ºå•ç‹¬çš„ "-"
                continue
            dash_positions.append(i)
        i += 1
    return dash_positions

def find_dash_positions(s,all_dash):
    dash_positions = []
    for i in all_dash:
        # è¾¹ç•Œæ£€æŸ¥
        is_space_before = i > 0 and s[i-1] == " "
        is_space_after = i < len(s) - 1 and s[i+1] == " "
        if is_space_before or is_space_after:
            dash_positions.append(i)
    return dash_positions

def split_relation(rel_seq):
    # --- ä¿æŒåŸå§‹çš„ split_relation é€»è¾‘ ---
    # æ³¨æ„: åŸå§‹é€»è¾‘æ¯”è¾ƒå¤æ‚ï¼Œå¯èƒ½éœ€è¦æ ¹æ®å®é™…å…³ç³»å­—ç¬¦ä¸²æ ¼å¼è¿›è¡Œè°ƒè¯•æˆ–ç®€åŒ–
    parts = []
    rel_seq = rel_seq.strip()
    all_dash = get_all_dash(rel_seq)
    right_arrows = find_right_arrow(rel_seq)
    left_arrows = find_left_arrow(rel_seq)
    dash_positions = find_dash_positions(rel_seq,all_dash)
    arrows_index = sorted(list(set(right_arrows+left_arrows))) # ä¿®æ­£: ä½¿ç”¨ set å»é‡

    if len(arrows_index) == 1:
        # å¤„ç†å•ç®­å¤´æƒ…å†µ
        arrow_pos = arrows_index[0]
        # ç¡®ä¿ dash_positions éç©º
        dash_pos = dash_positions[0] if dash_positions else -1
        if dash_pos == -1: return parts # æ— æ³•åˆ†å‰²

        if arrow_pos in right_arrows:
            source = rel_seq[:dash_pos].strip() # ä½¿ç”¨ç¬¬ä¸€ä¸ª dash
            rel = rel_seq[dash_pos+1:arrow_pos].strip()
            dst = rel_seq[arrow_pos+2:].strip()
            if source and rel and dst: parts.append((source,rel,dst))
        else: # left_arrow
            dst = rel_seq[:arrow_pos].strip()
            # å‡è®¾å…³ç³»åœ¨ç®­å¤´å’Œ dash ä¹‹é—´
            rel = rel_seq[arrow_pos+2:dash_pos].strip() # ä½¿ç”¨ç¬¬ä¸€ä¸ª dash
            source = rel_seq[dash_pos+1:].strip()
            if source and rel and dst: parts.append((source,rel,dst))
        return parts

    # åŸå§‹å¤šè·³åˆ†è§£é€»è¾‘ (éå¸¸å¤æ‚ï¼Œæ­¤å¤„ä¿ç•™ç»“æ„ï¼Œä½†å¯èƒ½éœ€è¦å¤§é‡è°ƒè¯•)
    # æ³¨æ„: ç´¢å¼•å¤„ç†å’Œè¾¹ç•Œæ¡ä»¶éœ€è¦éå¸¸å°å¿ƒ
    elif len(arrows_index) > 1 and len(dash_positions) >= len(arrows_index):
        i = 0
        try: # å¢åŠ  try-except å—æ•è·ç´¢å¼•é”™è¯¯
            for arrow_pos in arrows_index:
                if arrow_pos in right_arrows:
                    if i == 0:
                        source = rel_seq[:dash_positions[0]].strip()
                        rel = rel_seq[dash_positions[0]+1:arrow_pos].strip()
                        dst = rel_seq[arrow_pos+2:min(dash_positions[1],arrows_index[1])].strip()
                    elif i == len(arrows_index)-1:
                        source = rel_seq[max(dash_positions[i-1]+1,arrows_index[i-1]+2):dash_positions[-1]].strip()
                        rel = rel_seq[dash_positions[-1]+1:arrow_pos].strip()
                        dst = rel_seq[arrow_pos+2:].strip()
                    else:
                        source = rel_seq[max(dash_positions[i-1]+1,arrows_index[i-1]+2):dash_positions[i]].strip()
                        rel = rel_seq[dash_positions[i]+1:arrow_pos].strip()
                        dst = rel_seq[arrow_pos+2:min(dash_positions[i+1],arrows_index[i+1])].strip()
                elif arrow_pos in left_arrows: # left_arrow
                     if i == 0:
                        dst = rel_seq[:arrow_pos].strip()
                        rel = rel_seq[arrow_pos+2:dash_positions[i]].strip()
                        source = rel_seq[dash_positions[i]+1:min(dash_positions[i+1],arrows_index[i+1])].strip()
                     elif i == len(arrows_index)-1:
                        dst = rel_seq[max(arrows_index[i-1]+2,dash_positions[i-1]+1):arrow_pos].strip()
                        rel = rel_seq[arrow_pos+2:dash_positions[i]].strip() # ä½¿ç”¨ç¬¬ i ä¸ª dash
                        source = rel_seq[dash_positions[i]+1:].strip()
                     else:
                        dst = rel_seq[max(dash_positions[i-1]+1,arrows_index[i-1]+2):arrow_pos].strip()
                        rel = rel_seq[arrow_pos+2:dash_positions[i]].strip()
                        source = rel_seq[dash_positions[i]+1:min(dash_positions[i+1],arrows_index[i+1])].strip() # ä½¿ç”¨ç¬¬ i+1 ä¸ªå…ƒç´ 
                else: continue # Should not happen

                if source and rel and dst: parts.append((source, rel, dst))
                i += 1
        except IndexError as e:
            print(f"Error parsing multi-hop relation '{rel_seq}' due to index error: {e}")
            # å¯èƒ½è¿”å›éƒ¨åˆ†è§£æç»“æœæˆ–ç©ºåˆ—è¡¨
            return parts # è¿”å›å·²è§£æçš„éƒ¨åˆ†

    elif not parts and len(rel_seq) > 0: # å¦‚æœæ— æ³•è§£æ
        print(f"Warning: Could not parse relation (complex or unexpected format): {rel_seq}")

    return parts

def convert_rel_to_triplets(retrieve_results):
    triples = set()
    for rel_seq in retrieve_results:
        parsed_triples = split_relation(rel_seq)
        for t in parsed_triples:
                if len(t) == 3: # ç¡®ä¿æ˜¯æœ‰æ•ˆä¸‰å…ƒç»„
                    triples.add(t)
    return list(triples)

def triples_to_json(triples,evdience_entity,evdience_path):
    # --- ä¿æŒåŸå§‹çš„ triples_to_json é€»è¾‘ ---
    colors = [ "#FFB3BA", "#FFDFBA", "#FFFFBA", "#BAFFC9", "#BAE1FF", "#B5EAD7", "#ECC5FB", "#FFC3A0", "#FF9AA2", "#FFDAC1", "#E2F0CB", "#B5EAD7", "#C7CEEA", "#FFB7B2", "#FF9AA2", "#FFDAC1", "#C7CEEA", "#FFB3BA", "#FFDFBA", "#FFFFBA", "#BAFFC9", "#BAE1FF", "#FFC3A0", "#FF9AA2", "#FFDAC1", "#E2F0CB", "#B5EAD7", "#C7CEEA", "#FFB7B2", "#FF9AA2", "#FFDAC1", "#C7CEEA", "#FFB3BA", "#FFDFBA", "#FFFFBA", "#BAFFC9", "#BAE1FF", "#FFC3A0", "#FF9AA2", "#FFDAC1", "#E2F0CB", "#B5EAD7", "#C7CEEA", "#FFB7B2", "#FF9AA2", "#FFDAC1", "#C7CEEA", "#FFB3BA", "#FFDFBA", "#FFFFBA", "#BAFFC9", "#BAE1FF", "#FFC3A0", "#FF9AA2", "#FFDAC1" ]
    json_result = {'edges': [], 'nodes': [],'highlighted-edge':[],'highlighted-node':[]}
    node_set = set()
    import random
    # print(f"Triples:{triples}")

    for i, triple in enumerate(triples): # ä½¿ç”¨ enumerate è·å–ç´¢å¼•
        if len(triple) != 3: continue # è·³è¿‡æ— æ•ˆä¸‰å…ƒç»„
        source, relationship, destination = triple
        edge_id = f"e{i}" # ä¸ºè¾¹åˆ†é…å”¯ä¸€ ID
        color = colors[random.randint(0, len(colors)-1)] # ä¿®æ­£éšæœºé¢œè‰²ç´¢å¼•

        # æ·»åŠ è¾¹
        edge_data = { 'id': edge_id, 'label': relationship, 'source': source, 'target': destination, 'color': color } # æ·»åŠ  id
        json_result['edges'].append({ 'data': edge_data })
        if relationship in evdience_path:
            json_result['highlighted-edge'].append({'data': edge_data})

        # æ·»åŠ èŠ‚ç‚¹ (é¿å…é‡å¤)
        if source not in node_set:
            node_data_source = {'id': source, 'label': source, 'color': color} # åˆå§‹é¢œè‰²
            json_result['nodes'].append({'data': node_data_source})
            if source in evdience_entity:
                json_result['highlighted-node'].append({'data': node_data_source})
            node_set.add(source)
        elif source in evdience_entity and not any(n['data']['id'] == source for n in json_result['highlighted-node']):
            # å¦‚æœèŠ‚ç‚¹å·²å­˜åœ¨ä½†æœªé«˜äº®ï¼Œåˆ™é«˜äº®å®ƒ
             existing_node = next((n for n in json_result['nodes'] if n['data']['id'] == source), None)
             if existing_node: json_result['highlighted-node'].append(existing_node)

        if destination not in node_set:
            node_data_dest = {'id': destination, 'label': destination, 'color': color}
            json_result['nodes'].append({'data': node_data_dest})
            if destination in evdience_entity:
                json_result['highlighted-node'].append({'data': node_data_dest})
            node_set.add(destination)
        elif destination in evdience_entity and not any(n['data']['id'] == destination for n in json_result['highlighted-node']):
             existing_node = next((n for n in json_result['nodes'] if n['data']['id'] == destination), None)
             if existing_node: json_result['highlighted-node'].append(existing_node)

    return json_result

def get_evidence(file_path,item_id):
    # æ³¨æ„: åŒæ ·å­˜åœ¨ item_id ç±»å‹é—®é¢˜
    try:
        item_id_int = int(item_id)
    except (ValueError, TypeError):
        # print(f"Warning: get_evidence: Could not convert item_id '{item_id}' to integer.")
        return [], []

    try:
        with open(file_path, 'r') as file:
            data = json.load(file)
        e = next((item for item in data if item.get('id') == item_id_int), None)

        entity = set() # ä½¿ç”¨é›†åˆå»é‡
        path = set()
        if e and "merged_triplets" in e and isinstance(e["merged_triplets"], list):
            # éå† evidence ä¸­çš„æ¯ä¸ªä¸‰å…ƒç»„åˆ—è¡¨
            for t_list in e["merged_triplets"]:
                if isinstance(t_list, list):
                    # éå†åˆ—è¡¨ä¸­çš„æ¯ä¸ªä¸‰å…ƒç»„
                    for triple in t_list:
                        if isinstance(triple, list) and len(triple) == 3:
                            entity.add(triple[0])
                            path.add(triple[1])
                            entity.add(triple[2])
            return list(entity), list(path) # è½¬æ¢å›åˆ—è¡¨è¿”å›
        else:
            # print(f"No valid 'merged_triplets' found for id {item_id_int} in {file_path}")
            return [], []
    except FileNotFoundError:
         print(f"Evidence file not found: {file_path}")
         return [], []
    except Exception as ex:
        print(f"Error processing evidence file {file_path} for id {item_id}: {ex}")
        return [], []

# =========================================
# Flask è·¯ç”±
# =========================================

# --- åŸºæœ¬é¡µé¢è·¯ç”± ---
@app.route('/')
@login_required
def index(): 
    username = session.get('username')
    return render_template('demo.html')
@app.route('/login', methods=['GET'])
def login_page():
     if 'user_id' in session: return redirect(url_for('index'))
     return render_template('login.html')
@app.route('/register', methods=['GET'])
def register_page():
     if 'user_id' in session: return redirect(url_for('index'))
     return render_template('register.html')
@app.route('/analysis')
@login_required
def analysis(): return render_template('analysis.html')

# --- è®¤è¯ API ---
@app.route('/api/register', methods=['POST'])
def api_register():
    """å¤„ç†æ³¨å†Œè¯·æ±‚"""
    if not request.is_json: return jsonify({"error": "è¯·æ±‚å¿…é¡»æ˜¯ JSON"}), 415
    if not DB_INIT_SUCCESS: return jsonify({"error": "æ•°æ®åº“æœåŠ¡ä¸å¯ç”¨"}), 503
    data = request.get_json(); username, email, phone, password, confirm_password = map(data.get, ['username', 'email', 'phone', 'password', 'confirm_password']); errors = []
    if not all([username, email, phone, password, confirm_password]): errors.append("æ‰€æœ‰å­—æ®µéƒ½æ˜¯å¿…éœ€çš„ï¼")
    if password != confirm_password: errors.append("å¯†ç å’Œç¡®è®¤å¯†ç ä¸åŒ¹é…ï¼")
    if not errors:
        try: # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å­˜åœ¨
            if User.query.filter_by(username=username).first(): errors.append("ç”¨æˆ·åå·²å­˜åœ¨")
            if User.query.filter_by(email=email).first(): errors.append("é‚®ç®±å·²è¢«æ³¨å†Œ")
            if phone and User.query.filter_by(phone=phone).first(): errors.append("æ‰‹æœºå·å·²è¢«æ³¨å†Œ")
        except Exception as e: return jsonify({"error": "æ£€æŸ¥ç”¨æˆ·ä¿¡æ¯æ—¶æ•°æ®åº“å‡ºé”™ã€‚"}), 500
    if errors: return jsonify({"error": ", ".join(errors)}), 400
    try: # åˆ›å»ºç”¨æˆ·
        new_user = User(username=username, email=email, phone=phone); new_user.set_password(password)
        db.session.add(new_user); db.session.commit()
        return jsonify({"message": "æ³¨å†ŒæˆåŠŸï¼è¯·ç™»å½•ã€‚"}), 201
    except Exception as e: db.session.rollback(); return jsonify({"error": "æ³¨å†Œè¿‡ç¨‹ä¸­å‘ç”Ÿå†…éƒ¨é”™è¯¯ã€‚"}), 500

@app.route('/api/login', methods=['POST'])
def api_login():
    """å¤„ç†ç™»å½•è¯·æ±‚"""
    if not request.is_json: return jsonify({"error": "è¯·æ±‚å¿…é¡»æ˜¯ JSON"}), 415
    if not DB_INIT_SUCCESS: return jsonify({"error": "æ•°æ®åº“æœåŠ¡ä¸å¯ç”¨"}), 503
    data = request.get_json(); username, password = data.get('username'), data.get('password')
    if not username or not password: return jsonify({"error": "ç”¨æˆ·åå’Œå¯†ç æ˜¯å¿…éœ€çš„ï¼"}), 400
    try:
        user = User.query.filter_by(username=username).first()
        if user and user.check_password(password):
            session.clear(); session['user_id'] = user.id; session['username'] = user.username
            
            return jsonify({"message": "ç™»å½•æˆåŠŸï¼"}), 200
        else: return jsonify({"error": "æ— æ•ˆçš„ç”¨æˆ·åæˆ–å¯†ç "}), 401
    except Exception as e: return jsonify({"error": "ç™»å½•è¿‡ç¨‹ä¸­å‘ç”Ÿå†…éƒ¨é”™è¯¯ã€‚"}), 500

@app.route('/api/logout', methods=['POST'])
@login_required
def api_logout():
    """å¤„ç†ç™»å‡ºè¯·æ±‚"""
    session.clear()
    return jsonify({"message": "æ³¨é”€æˆåŠŸ"}), 200

@app.route('/api/check-auth', methods=['GET'])
def api_check_auth():
    """æ£€æŸ¥ç”¨æˆ·ç™»å½•çŠ¶æ€"""
    if 'user_id' in session: return jsonify({"logged_in": True, "user_id": session['user_id'], "username": session.get('username')}), 200
    else: return jsonify({"logged_in": False}), 200

# --- å†å²è®°å½• / ä¼šè¯ API ---
@app.route('/api/sessions', methods=['POST'])
@login_required
def create_session_api():
    """åˆ›å»ºæ–°ä¼šè¯ï¼ŒåŒ…å«è¡¨æ•°é‡é™åˆ¶æ£€æŸ¥"""
    user_id = session['user_id']
    if not request.is_json: 
        return jsonify({"error": "è¯·æ±‚å¿…é¡»æ˜¯ JSON"}), 415
    if not DB_INIT_SUCCESS: 
        return jsonify({"error": "æ•°æ®åº“æœåŠ¡ä¸å¯ç”¨"}), 503
    
    data = request.get_json()
    session_name = data.get("sessionName", "").strip() or f"ä¼šè¯ {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}"
    
    try:
        # æ£€æŸ¥ç”¨æˆ·ä¼šè¯æ•°é‡
        existing_count = ChatSession.query.filter_by(user_id=user_id).count()
        if existing_count >= 5:
            return jsonify({"error": "å·²è¾¾åˆ°æœ€å¤§å¯¹è¯è¡¨æ•°é‡é™åˆ¶(5ä¸ª)"}), 400
        
        new_session = ChatSession(user_id=user_id, session_name=session_name)
        db.session.add(new_session)
        db.session.commit()
        
        return jsonify({
            "id": new_session.id, 
            "name": new_session.session_name, 
            "create_time": new_session.create_time.isoformat()+'Z'
        }), 201
    except Exception as e: 
        db.session.rollback()
        return jsonify({"error": "åˆ›å»ºä¼šè¯æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯"}), 500

@app.route('/api/sessions/<int:session_id>', methods=['DELETE'])
@login_required
def delete_session_api(session_id):
    """åˆ é™¤æŒ‡å®šä¼šè¯"""
    user_id = session['user_id']
    if not DB_INIT_SUCCESS: 
        return jsonify({"error": "æ•°æ®åº“æœåŠ¡ä¸å¯ç”¨"}), 503
    
    try:
        # éªŒè¯ä¼šè¯å½’å±
        chat_session = ChatSession.query.filter_by(id=session_id, user_id=user_id).first()
        if not chat_session:
            return jsonify({"error": "ä¼šè¯æœªæ‰¾åˆ°æˆ–æ— æƒé™"}), 404
        
        # åˆ é™¤ä¼šè¯åŠå…¶æ¶ˆæ¯
        ChatMessage.query.filter_by(session_id=session_id).delete()
        db.session.delete(chat_session)
        db.session.commit()
        
        return jsonify({"message": "ä¼šè¯åˆ é™¤æˆåŠŸ"}), 200
    except Exception as e: 
        db.session.rollback()
        return jsonify({"error": "åˆ é™¤ä¼šè¯æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯"}), 500

@app.route('/delete-history-session', methods=['DELETE'])
@login_required
def delete_history_session():
    """åˆ é™¤æŒ‡å®šå†å²ä¼šè¯ï¼ˆé€šè¿‡ä¼šè¯åç§°ï¼‰"""
    user_id = session['user_id']
    data = request.get_json()
    session_name = data.get('sessionName')
    dataset_name = data.get('datasetName')
    
    if not session_name:
        return jsonify({"error": "ä¼šè¯åç§°ä¸èƒ½ä¸ºç©º"}), 400
    
    if not DB_INIT_SUCCESS:
        return jsonify({"error": "æ•°æ®åº“æœåŠ¡ä¸å¯ç”¨"}), 503
    
    try:
        # æŸ¥æ‰¾å¯¹åº”çš„ä¼šè¯
        chat_session = ChatSession.query.filter_by(
            name=session_name,
            user_id=user_id
        ).first()
        
        if not chat_session:
            return jsonify({"error": "ä¼šè¯æœªæ‰¾åˆ°æˆ–æ— æƒé™"}), 404
        
        # åˆ é™¤ä¼šè¯åŠå…¶æ‰€æœ‰æ¶ˆæ¯
        ChatMessage.query.filter_by(session_id=chat_session.id).delete()
        db.session.delete(chat_session)
        db.session.commit()
        
        return jsonify({"message": f"ä¼šè¯ '{session_name}' åˆ é™¤æˆåŠŸ"}), 200
    except Exception as e:
        db.session.rollback()
        app.logger.error(f"åˆ é™¤ä¼šè¯å¤±è´¥: {str(e)}")
        return jsonify({"error": "åˆ é™¤ä¼šè¯æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯"}), 500

@app.route('/api/sessions/<int:session_id>/history', methods=['GET'])
@login_required
def get_session_history(session_id):
    """è·å–æŒ‡å®šä¼šè¯çš„å†å²è®°å½• (éªŒè¯æ‰€æœ‰æƒ)"""
    user_id = session['user_id']
    if not DB_INIT_SUCCESS: return jsonify({"error": "æ•°æ®åº“æœåŠ¡ä¸å¯ç”¨"}), 503
    try:
        chat_session = ChatSession.query.filter_by(id=session_id, user_id=user_id).first()
        if not chat_session: return jsonify({"error": "ä¼šè¯æœªæ‰¾åˆ°æˆ–æ— æƒè®¿é—®"}), 404
        messages = ChatMessage.query.filter_by(session_id=session_id).order_by(ChatMessage.timestamp.asc()).all()
        return jsonify([msg.to_dict() for msg in messages])
    except Exception as e: return jsonify({"error": "è·å–å†å²è®°å½•æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯"}), 500
    


# --- RAG æ ¸å¿ƒäº¤äº’ API ---
@app.route('/load_model', methods=['POST'])
@login_required
def load_model():
    global current_model
    try:
        data = request.json
        mode = data.get("mode")
        if mode == "Stop":
            # å‡è®¾ Demo_chat ä¸­æœ‰ close() æ–¹æ³•æ¥åœæ­¢æ¨¡å‹çš„æ“ä½œ
            if current_model is not None:
                print("Stopping the current model.")
                current_model.close()  # è°ƒç”¨ Demo_chat ä¸­çš„å…³é—­æ¨¡å‹çš„æ–¹æ³•
                current_model = None
                return jsonify({"status": "success", "message": "æ¨¡å‹å·²åœæ­¢"}), 200
            else:
                return jsonify({"status": "error", "message": "æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„æ¨¡å‹"}), 400
        
        model_name = data.get("model_name")
        key = data.get("key")
        dataset_info = data.get("dataset")
        hop = dataset_info.get('hop')
        type = dataset_info.get('type')
        entity = dataset_info.get('entity')
        dataset = dataset_info.get('dataset')
        session = dataset_info.get('session')
        dataset_path = f"../data/{hop}/{type}/{entity}/{dataset}/{dataset}.json"  
        if key == "" or key is None:  # å¤„ç†ç©ºæˆ– None çš„ key
            key = "ollama"  # é»˜è®¤ key
        print(f"Received /load_model: model={model_name}, key={'<default_ollama>' if key=='ollama' else '<provided>'}, dataset={dataset}")

        if not model_name:
            return jsonify({"status": "error", "message": "ç¼ºå°‘æ¨¡å‹åç§°"}), 400
        if not dataset:
            print("Warning: Dataset parameter is missing in /load_model request.")
        
        print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_name} (API Key: {'*'*(len(key)-3)+key[-3:] if key != 'ollama' and key else 'ollama'}, æ•°æ®é›†: {dataset})")
        current_model = Demo_chat(model_name=model_name, api_key=key, dataset_name=dataset, dataset_path=dataset_path, path_name=session)

        

        def generate():
            # å‘é€åˆå§‹çŠ¶æ€
            yield json.dumps({"status": "start", "message": f"æ¨¡å‹ {model_name} (æ•°æ®é›†: {dataset}) åŠ è½½æˆåŠŸ"}) + "\n"
            
            # å¤„ç†æ¯ä¸ªé¡¹ç›®å¹¶ç«‹å³å‘é€
            for item_data in current_model.new_history_chat(mode = mode):
                yield json.dumps({"status": "processing", "item_data": item_data}) + "\n"
            
            # å‘é€å®ŒæˆçŠ¶æ€
            yield json.dumps({"status": "complete", "message": "æ‰€æœ‰é¡¹ç›®å¤„ç†å®Œæˆ"}) + "\n"

        return Response(generate(), mimetype='text/event-stream')


    except Exception as e:
        print(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}")
        traceback.print_exc()
        return jsonify({"status": "error", "message": str(e)}), 500


# @app.route('/generate', methods=['POST'])
# @login_required
# def generate_answers():
#     """å¤„ç† RAG ç”Ÿæˆè¯·æ±‚å¹¶ä¿å­˜å†å²"""
#     global current_model
#     if not RAG_CORE_LOADED or current_model is None: return jsonify({"error": "æ¨¡å‹æœªåŠ è½½æˆ–ä¸å¯ç”¨"}), 501
#     if not request.is_json: return jsonify({"error": "è¯·æ±‚å¿…é¡»æ˜¯ JSON"}), 415
#     if not DB_INIT_SUCCESS: return jsonify({"error": "æ•°æ®åº“æœåŠ¡ä¸å¯ç”¨"}), 503

#     try:
#         data = request.json; user_input, session_id, rag_mode = data.get("input"), data.get("session_id"), data.get("rag_mode", "hybrid")
#         if not user_input or not session_id: return jsonify({"error": "ç¼ºå°‘è¾“å…¥æˆ– Session ID"}), 400
#         user_id = session['user_id']; chat_session = ChatSession.query.filter_by(id=session_id, user_id=user_id).first()
#         if not chat_session: return jsonify({"error": "ä¼šè¯æœªæ‰¾åˆ°æˆ–æ— æƒè®¿é—®"}), 404

#         # --- è°ƒç”¨ RAG æ ¸å¿ƒ ---
#         generated_details = {}; raw_graph_strings = None; vector_retrieval = None
#         try:
#              # *** ä½ éœ€è¦æ ¹æ®ä½ çš„ Demo_chat å®ç°è°ƒæ•´è¿™é‡Œ ***
#              generated_details["vector_response"] = current_model.chat(user_input, mode='vector')
#              generated_details["graph_response"] = current_model.chat(user_input, mode='graph')
#              generated_details["hybrid_response"] = current_model.chat(user_input, mode='hybrid')
#              # *** è·å–çœŸå®çš„æ£€ç´¢ç»“æœ (éœ€è¦ä½ çš„ç±»æ”¯æŒ) ***
#              if hasattr(current_model, 'get_last_raw_graph_strings'): raw_graph_strings = current_model.get_last_raw_graph_strings()
#              if hasattr(current_model, 'get_last_retrieval_results'): vector_retrieval = current_model.get_last_retrieval_results('vector')
#              generated_details["vector_retrieval_result"] = vector_retrieval
#         except Exception as chat_err: return jsonify({"error": f"ç”Ÿæˆå›ç­”æ—¶æ ¸å¿ƒæ¨¡å—å‡ºé”™ï¼š{chat_err}"}), 500

#         # --- ä¿å­˜åˆ°æ•°æ®åº“ ---
#         message_id_saved, timestamp_saved = None, None
#         try:
#             new_message = ChatMessage(
#                 session_id=session_id, query=user_input,
#                 vector_response=generated_details.get("vector_response"), graph_response=generated_details.get("graph_response"), hybrid_response=generated_details.get("hybrid_response"),
#                 vector_retrieval_json=json.dumps(vector_retrieval) if vector_retrieval is not None else None,
#                 graph_retrieval_raw=json.dumps(raw_graph_strings) if raw_graph_strings is not None else None, # ä¿å­˜åŸå§‹å›¾è°±å­—ç¬¦ä¸²
#                 rag_mode_used=rag_mode )
#             db.session.add(new_message); db.session.commit()
#             message_id_saved, timestamp_saved = new_message.id, new_message.timestamp.isoformat() + 'Z'
#         except Exception as db_err: db.session.rollback(); return jsonify({"error": "ä¿å­˜å†å²è®°å½•æ—¶å‡ºé”™"}), 500

#         # --- è¿”å›ç»“æœ ---
#         return jsonify({ "query": user_input, "vectorAnswer": generated_details.get("vector_response"), "graphAnswer": generated_details.get("graph_response"), "hybridAnswer": generated_details.get("hybrid_response"), "message_id": message_id_saved, "timestamp": timestamp_saved }), 200
#     except Exception as e: return jsonify({"error": f"å¤„ç†ç”Ÿæˆè¯·æ±‚æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ï¼š{str(e)}"}), 500

# --- æ ¼å¼åŒ– SSE è¾“å‡º ---
def sse_pack(data_dict: dict) -> str:
    """å°†å­—å…¸æ ¼å¼åŒ–ä¸º Server-Sent Event (SSE) data å­—æ®µ"""
    return f"data: {json.dumps(data_dict)}\n\n"

@app.route('/generate', methods=['POST'])
@login_required
def generate_answers():
    global current_model
    
    if not RAG_CORE_LOADED or current_model is None:
        return Response(sse_pack({"type": "error", "message": "æ¨¡å‹æœªåŠ è½½æˆ–å½“å‰ä¸å¯ç”¨"}), mimetype='text/event-stream', status=501)
    if not request.is_json:
        return Response(sse_pack({"type": "error", "message": "è¯·æ±‚å¿…é¡»æ˜¯ JSON æ ¼å¼"}), mimetype='text/event-stream', status=415)
    if not DB_INIT_SUCCESS:
        return Response(sse_pack({"type": "error", "message": "æ•°æ®åº“æœåŠ¡å½“å‰ä¸å¯ç”¨"}), mimetype='text/event-stream', status=503)

    try:
        data = request.json
        user_input = data.get("input")
        session_id_str = data.get("session_id")
        rag_mode_to_stream = data.get("rag_mode", "hybrid") # å®¢æˆ·ç«¯æŒ‡å®šè¦æµå¼è·å–çš„æ¨¡å¼

        if rag_mode_to_stream not in ['vector', 'graph', 'hybrid']:
             return Response(sse_pack({"type": "error", "message": "æ— æ•ˆçš„ RAG æ¨¡å¼è¯·æ±‚"}), mimetype='text/event-stream', status=400)

        if not user_input or not session_id_str:
            return Response(sse_pack({"type": "error", "message": "ç¼ºå°‘ç”¨æˆ·è¾“å…¥æˆ–ä¼šè¯ ID"}), mimetype='text/event-stream', status=400)

        user_id = session['user_id']
        try:
            session_id_int = int(session_id_str)
        except ValueError:
            return Response(sse_pack({"type": "error", "message": "æ— æ•ˆçš„ä¼šè¯ ID æ ¼å¼"}), mimetype='text/event-stream', status=400)
            
        chat_session = ChatSession.query.filter_by(id=session_id_int, user_id=user_id).first()
        if not chat_session:
            return Response(sse_pack({"type": "error", "message": "ä¼šè¯æœªæ‰¾åˆ°æˆ–æ‚¨æ— æƒè®¿é—®æ­¤ä¼šè¯"}), mimetype='text/event-stream', status=404)

        # --- æµå¼ç”Ÿæˆå™¨å‡½æ•° ---
        def event_stream_generator():
            full_streamed_response_content = []
            # è¿™äº›å˜é‡ç”¨äºå­˜å‚¨å„ä¸ªRAGæµç¨‹çš„æ£€ç´¢ç»“æœï¼Œä»¥ä¾¿åç»­ä¿å­˜æ•°æ®åº“
            # æ‚¨éœ€è¦è°ƒæ•´ Demo_chat æˆ–å…¶ç»„ä»¶ï¼Œä½¿å…¶åœ¨æ‰§è¡Œæ£€ç´¢åèƒ½æä¾›è¿™äº›ä¿¡æ¯
            current_vector_retrieval_for_db = None
            current_graph_retrieval_for_db = None
            current_hybrid_context_for_db = None # æ··åˆæ¨¡å¼å¯èƒ½ä½¿ç”¨ç‰¹å®šçš„ç»„åˆä¸Šä¸‹æ–‡
            
            error_during_rag_call = None

            try:
                # **å…³é”®æ­¥éª¤ï¼šè°ƒç”¨ Demo_chat ä¸­ç»æ”¹é€ æˆ–æ–°å¢çš„ã€æ”¯æŒæµå¼çš„æ–¹æ³•**
                # ä¸‹é¢çš„è°ƒç”¨æ˜¯å‡è®¾æ€§çš„ï¼Œæ‚¨éœ€è¦æ ¹æ® Demo_chat.py çš„å®é™…æƒ…å†µè°ƒæ•´æˆ–å®ç°ï¼š
                
                # å‡è®¾1: Demo_chat ç±»æœ‰ä¸€ä¸ªç»Ÿä¸€çš„æµå¼èŠå¤©æ–¹æ³•
                # def stream_chat(self, message, mode, history=None) -> generator:
                #     # 1. æ ¹æ® mode è·å–æ£€ç´¢ä¸Šä¸‹æ–‡ (vector_ctx, graph_ctx)
                #     # 2. å­˜å‚¨è¿™äº›ä¸Šä¸‹æ–‡åˆ° self çš„ä¸´æ—¶å˜é‡ï¼Œä¾›åç»­ get_last_retrieval_results è·å–
                #     # 3. æ„å»º prompt
                #     # 4. yield from self.llm.chat_with_ai_stream(prompt, history)
                
                # å‡è®¾2: æˆ–è€…ï¼Œæˆ‘ä»¬ç›´æ¥åœ¨ app.py ä¸­ç¼–æ’ï¼Œä½†æ›´æ¨èå°è£…åœ¨ Demo_chat ä¸­
                # ä¸ºç®€åŒ–ï¼Œæˆ‘ä»¬å‡è®¾ current_model æœ‰ä¸€ä¸ªæ”¹é€ åçš„ .chat() æ–¹æ³•ï¼Œæˆ–è€…ä¸€ä¸ªæ–°çš„æµå¼æ–¹æ³•
                
                prompt_for_llm = ""
                history_for_llm = [] # å¯é€‰ï¼Œä»æ•°æ®åº“åŠ è½½å†å²

                # 1. æ ¹æ® rag_mode_to_stream è·å–ä¸Šä¸‹æ–‡å¹¶æ„å»º Prompt
                #    è¿™éƒ¨åˆ†é€»è¾‘ç›®å‰åœ¨ Demo_chat.py çš„å„ä¸ª chat æ–¹æ³•ä¸­ï¼Œéœ€è¦æå–æˆ–æ”¹é€ 
                if rag_mode_to_stream == "vector":
                    # å‡è®¾: current_model.chat_vector.prepare_streaming_context(user_input) è¿”å› (prompt, retrieval_data)
                    # æˆ–è€… current_model.chat_vector.get_retrieval_context()
                    # prompt_for_llm, current_vector_retrieval_for_db = current_model.chat_vector.some_method_to_get_prompt_and_retrieval(user_input)
                    # ä¸ºç¤ºæ„ï¼Œæˆ‘ä»¬ç›´æ¥è°ƒç”¨å…¶web_chatï¼Œä½†ç†æƒ³æƒ…å†µä¸‹web_chatåº”èƒ½è¿”å›æµ
                    # è¿™æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„ç®€åŒ–å’Œå‡è®¾ï¼Œå®é™…éœ€è¦é‡æ„ ChatVectorRAG ç­‰ç±»
                    # ---- æ¦‚å¿µæ€§ä»£ç å¼€å§‹ ----
                    if hasattr(current_model.chat_vector, 'get_context_and_prompt'): # ç†æƒ³çš„æ¥å£
                        prompt_for_llm, current_vector_retrieval_for_db = current_model.chat_vector.get_context_and_prompt(user_input, history_for_llm)
                    else: # å¦‚æœæ²¡æœ‰ï¼Œéœ€è¦æ‚¨åœ¨ Demo_chat æˆ– ChatVectorRAG ä¸­å®ç°
                        # æ¨¡æ‹Ÿï¼šè·å–ä¸Šä¸‹æ–‡ï¼Œç„¶åæ„å»ºprompt
                        # current_vector_retrieval_for_db = current_model.chat_vector.retrieval_result() # è¿™å¯èƒ½ä¸æ­£ç¡®ï¼Œå› ä¸ºå®ƒå¯èƒ½æ˜¯ä¸Šæ¬¡è°ƒç”¨çš„ç»“æœ
                        # prompt_for_llm = current_model.chat_vector._build_prompt(user_input, current_vector_retrieval_for_db, history_for_llm)
                        raise NotImplementedError("Demo_chat æˆ–å…¶ç»„ä»¶éœ€è¦æä¾›è·å–RAGä¸Šä¸‹æ–‡å’Œå¯¹åº”Promptçš„æ–¹æ³•ä»¥æ”¯æŒæµå¼è¾“å‡º")
                    # ---- æ¦‚å¿µæ€§ä»£ç ç»“æŸ ----

                elif rag_mode_to_stream == "graph":
                    # ç±»ä¼¼åœ°å¤„ç† graph RAG
                    # prompt_for_llm, current_graph_retrieval_for_db = current_model.chat_graph.some_method_to_get_prompt_and_retrieval(user_input)
                    raise NotImplementedError("Graph RAG æµå¼ä¸Šä¸‹æ–‡å’ŒPromptè·å–é€»è¾‘æœªå®ç°")
                
                elif rag_mode_to_stream == "hybrid":
                    # hybrid æ¨¡å¼çš„ä¸Šä¸‹æ–‡å‡†å¤‡å’Œ prompt æ„å»º
                    # prompt_for_llm, current_hybrid_context_for_db = current_model.prepare_hybrid_prompt_and_retrieval(user_input)
                    raise NotImplementedError("Hybrid RAG æµå¼ä¸Šä¸‹æ–‡å’ŒPromptè·å–é€»è¾‘æœªå®ç°")

                elif rag_mode_to_stream == "without_rag":
                    # ChatWithoutRAG = getattr(sys.modules.get('chat.chat_withoutrag'), 'ChatWithoutRAG', None) # åŠ¨æ€è·å–ç±»
                    # if ChatWithoutRAG:
                    #     no_rag_chat_instance = ChatWithoutRAG(current_model.llm)
                    #     prompt_for_llm = no_rag_chat_instance._build_prompt(user_input, history_for_llm) # å‡è®¾æœ‰æ­¤æ–¹æ³•
                    # else:
                    #     raise ImportError("ChatWithoutRAG ç±»æœªæ‰¾åˆ°æˆ–æœªå¯¼å…¥")
                    # ä¸ºç®€åŒ–ï¼Œç›´æ¥ä½¿ç”¨ä¸€ä¸ªç®€å•prompt
                    prompt_for_llm = user_input # æœ€ç®€å•çš„æ— RAGæƒ…å†µ
                
                # 2. è°ƒç”¨åº•å±‚çš„LLMæµå¼æ¥å£
                print(f"å‘LLMå‘é€æµå¼è¯·æ±‚ (æ¨¡å¼: {rag_mode_to_stream}), Prompt: {prompt_for_llm[:100]}...")
                # å‡è®¾ self.llm æ˜¯ Demo_chat ä¸­åˆå§‹åŒ–çš„ LLM Client å®ä¾‹
                answer_stream = current_model.llm.chat_with_ai_stream(prompt=prompt_for_llm, history=history_for_llm)

                for chunk_obj in answer_stream: # LLM Client è¿”å›çš„åŸå§‹ chunk å¯¹è±¡
                    # è§£æ chunk_obj ä»¥è·å–æ–‡æœ¬å†…å®¹ï¼Œè¿™å–å†³äºæ‚¨çš„ LLM Client å®ç°
                    # ä¾‹å¦‚ï¼Œå¯¹äº OpenAI å…¼å®¹çš„å®¢æˆ·ç«¯:
                    chunk_content = ""
                    if hasattr(chunk_obj, 'choices') and chunk_obj.choices:
                        delta = chunk_obj.choices[0].delta
                        if hasattr(delta, 'content') and delta.content is not None:
                            chunk_content = delta.content
                    
                    if chunk_content:
                        full_streamed_response_content.append(chunk_content)
                        yield sse_pack({"type": "chunk", "content": chunk_content})
                        # time.sleep(0.01) 

            except NotImplementedError as nie: # æ•è·æˆ‘ä»¬è‡ªå·±æŠ›å‡ºçš„æœªå®ç°é”™è¯¯
                error_during_rag_call = f"åŠŸèƒ½å®ç°ä¸­: {str(nie)}"
                print(error_during_rag_call)
                yield sse_pack({"type": "error", "message": error_during_rag_call})
            except Exception as e:
                error_during_rag_call = f"ç”Ÿæˆå›ç­”æ—¶æ ¸å¿ƒæ¨¡å—å‡ºé”™: {str(e)}"
                print(error_during_rag_call)
                traceback.print_exc()
                yield sse_pack({"type": "error", "message": "å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯ã€‚"})
            
            # --- æµç»“æŸ ---
            if error_during_rag_call:
                yield sse_pack({"type": "end", "status": "error_rag_core", "message": error_during_rag_call})
                return

            final_streamed_answer = "".join(full_streamed_response_content)
            print(f"æ¨¡å¼ '{rag_mode_to_stream}' æµå¼å›ç­”å®Œæˆã€‚")

            # --- [é‡è¦] è·å–ç”¨äºæ•°æ®åº“ä¿å­˜çš„å®Œæ•´ä¿¡æ¯ ---
            # æ­¤æ—¶ï¼Œfinal_streamed_answer æ˜¯æµå¼æ¨¡å¼çš„å®Œæ•´ç­”æ¡ˆã€‚
            # æˆ‘ä»¬è¿˜éœ€è¦å…¶ä»–æ¨¡å¼çš„ç­”æ¡ˆä»¥åŠæ‰€æœ‰ç›¸å…³çš„æ£€ç´¢ä¿¡æ¯æ‰èƒ½å®Œæ•´ä¿å­˜ ChatMessageã€‚
            
            # (æ­¤éƒ¨åˆ†é€»è¾‘ä¸ä¸Šä¸€è½®å›å¤ä¸­çš„éæµå¼ /generate ç±»ä¼¼ï¼Œåœ¨æµç»“æŸåè·å–)
            all_responses_for_db = { "vector_response": None, "graph_response": None, "hybrid_response": None }
            all_responses_for_db[f"{rag_mode_to_stream}_response"] = final_streamed_answer

            # åŒæ­¥è·å–å…¶ä»–æ¨¡å¼çš„ç­”æ¡ˆï¼ˆå¦‚æœéœ€è¦ï¼‰
            # ... (çœç•¥è¿™éƒ¨åˆ†ä»£ç ï¼Œå‚è€ƒä¸Šä¸€è½®å›å¤ä¸­çš„å®ç°ï¼Œå®ƒä¼šè°ƒç”¨ current_model.chat(stream=False))
            # ... (ä»¥åŠè·å– current_vector_retrieval_for_db, current_graph_retrieval_for_db çš„é€»è¾‘)
            # ä¸ºç¡®ä¿èƒ½è¿è¡Œï¼Œæš‚æ—¶å°†å…¶ä»–æ¨¡å¼çš„å›ç­”å’Œæ£€ç´¢ç»“æœè®¾ä¸ºå ä½ç¬¦æˆ–ä»æµå¼æ¨¡å¼çš„ç»“æœæ¨æ–­
            # æ‚¨éœ€è¦æ ¹æ®å®é™…éœ€æ±‚å®Œå–„è¿™é‡Œ
            if rag_mode_to_stream != "vector":
                 all_responses_for_db["vector_response"] = "åŒæ­¥è·å–vectorç­”æ¡ˆï¼ˆå¾…å®ç°ï¼‰"
            if rag_mode_to_stream != "graph":
                 all_responses_for_db["graph_response"] = "åŒæ­¥è·å–graphç­”æ¡ˆï¼ˆå¾…å®ç°ï¼‰"
            if rag_mode_to_stream != "hybrid":
                 all_responses_for_db["hybrid_response"] = "åŒæ­¥è·å–hybridç­”æ¡ˆï¼ˆå¾…å®ç°ï¼‰"
            
            # å‡è®¾æ£€ç´¢ç»“æœå¯ä»¥é€šè¿‡æŸç§æ–¹å¼è·å–ï¼Œè¿™é‡Œç”¨å ä½ç¬¦
            # current_vector_retrieval_for_db = current_model.get_last_retrieval_results('vector') if hasattr(current_model, 'get_last_retrieval_results') else None
            # current_graph_retrieval_for_db = current_model.get_last_raw_graph_strings() if hasattr(current_model, 'get_last_raw_graph_strings') else None


            # --- å°†äº¤äº’ç»“æœä¿å­˜åˆ°æ•°æ®åº“ ---
            message_id_saved = None; timestamp_saved_iso = None; db_save_error_message = None
            try:
                print("å‡†å¤‡å°†èŠå¤©è®°å½•ä¿å­˜åˆ°æ•°æ®åº“...")
                new_message = ChatMessage(
                    session_id=session_id_int, query=user_input,
                    vector_response=all_responses_for_db.get("vector_response"),
                    graph_response=all_responses_for_db.get("graph_response"),
                    hybrid_response=all_responses_for_db.get("hybrid_response"),
                    vector_retrieval_json=json.dumps(current_vector_retrieval_for_db) if current_vector_retrieval_for_db else None,
                    graph_retrieval_raw=json.dumps(current_graph_retrieval_for_db) if current_graph_retrieval_for_db else None,
                    rag_mode_used=rag_mode_to_stream
                )
                db.session.add(new_message)
                db.session.commit()
                message_id_saved = new_message.id
                timestamp_saved_iso = new_message.timestamp.isoformat() + 'Z'
                print(f"èŠå¤©è®°å½• {message_id_saved} å·²æˆåŠŸä¿å­˜ã€‚")
            except Exception as db_err:
                db.session.rollback()
                db_save_error_message = "æœªèƒ½æˆåŠŸå°†æ­¤æ¡èŠå¤©è®°å½•ä¿å­˜åˆ°æ•°æ®åº“ã€‚"
                print(f"æ•°æ®åº“ä¿å­˜é”™è¯¯: {db_err}"); traceback.print_exc()

            final_sse_payload = {"type": "end", "status": "success" if not db_save_error_message else "warning_dbsave_failed",
                                 "message_id": message_id_saved, "timestamp": timestamp_saved_iso}
            if db_save_error_message: final_sse_payload["db_error"] = db_save_error_message
            yield sse_pack(final_sse_payload)
            print("æµå¼å“åº”å’Œæ•°æ®åº“æ“ä½œå®Œæˆã€‚")

        return Response(event_stream_generator(), mimetype='text/event-stream')

    except Exception as setup_e:
        error_message = f"å¤„ç† /generate è¯·æ±‚æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ (æµå¼€å§‹å‰): {str(setup_e)}"
        print(error_message); traceback.print_exc()
        def error_stream_response(): yield sse_pack({"type": "error", "message": f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(setup_e)}"})
        return Response(error_stream_response(), mimetype='text/event-stream', status=500)

@app.route('/read-file', methods=['GET'])
def read_file():
    try:
        # è®¾å®šæ–‡ä»¶è·¯å¾„ (è¿™ä¸ªè·¯å¾„å¯èƒ½æ˜¯å›ºå®šçš„ï¼Œæˆ–è€…åº”è¯¥ä½œä¸ºå‚æ•°?)
        file_path = '/home/lipz/NeutronRAG/NeutronRAG/backend/evaluator/rgb/test.json'
        with open(file_path, 'r') as file:
            data = json.load(file)
        result = []
        for item in data:
            result.append({
                'id': item.get('id'),
                'question': item.get('question'),
                'answer': item.get('answer'),
                'hybrid_response': item.get('hybrid_response'),
                'type' : item.get('type')
            })
        return jsonify({'content': result})
    except Exception as e:
        print(f"Error reading file {file_path}: {e}")
        return jsonify({'error': str(e)}), 500
    
#é€šè¿‡ç”¨æˆ·åå­—åœ¨æ•°æ®è¡¨ä¸­æŒ‡å®šï¼Œæ˜¾ç¤ºå‡ºè¯¥ç”¨æˆ·çš„æ‰€æœ‰å¯¹è¯å†å²table    
# è¿”å›ç¤ºä¾‹
# {
#   "user_name": "Alice",
#   "user_id": "u_123",
#   "history_tables": ["test1", "eval_0429", "final"]
# }

@app.route("/get-history-tables", methods=["GET"])
def get_history_table():
    """
    é€šè¿‡ session ä¸­çš„ user_nameï¼Œè¿”å›è¯¥ç”¨æˆ·æ‰€æœ‰å†å²è¡¨åç¼€
    """
    user_name = session.get("username")
    user_id = session.get("user_id")
    if not user_name:
        return jsonify({"error": "æœªç™»å½•ï¼Œæ— æ³•è·å– username"}), 401

    try:
        print("##########å¼€å§‹æŸ¥è¯¢########")
        print(user_name,"#####################")
        # æŸ¥è¯¢ user_id
        suffixes = mysql.get_user_history_suffixes(str(user_id))
        print(suffixes)
        print("ç»“æŸæŸ¥è¯¢userè¡¨")

        return jsonify({
            "user_name": user_name,
            "id": user_id,
            "history_tables": suffixes
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 500



@app.route("/get-history-entries")
@login_required
def get_history_entries():
    table_suffix = request.args.get("table_suffix")
    user_id = session.get("user_id")

    if not table_suffix or not user_id:
        return jsonify({"entries": [], "error": "ç¼ºå°‘å‚æ•° table_suffix æˆ–ç”¨æˆ·æœªç™»å½•"}), 400

    table_name = f"user{user_id}_history_{table_suffix}"

    try:
        print(f"ğŸ“¥ å¼€å§‹æŸ¥è¯¢å†å²è®°å½•è¡¨ `{table_name}`")
        cursor = mysql.cursor
        cursor.execute(f"""
            SELECT id, query, answer, type,
                   vector_response, graph_response, hybrid_response
            FROM `{table_name}`
            ORDER BY created_at DESC
            LIMIT 100
        """)
        rows = cursor.fetchall()

        entries = []
        for row in rows:
            entries.append({
                "id": row[0],
                "query": row[1],
                "answer": row[2],
                "type": row[3],
                "vector_response": row[4],
                "graph_response": row[5],
                "hybrid_response": row[6],
            })

        print(f"âœ… æŸ¥è¯¢æˆåŠŸï¼Œå…±è¿”å› {len(entries)} æ¡è®°å½•")
        return jsonify({"entries": entries})

    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
        return jsonify({"entries": [], "error": str(e)}), 500





@app.route('/get-vector/<item_id>', methods=['GET'])
@login_required
def get_vector(item_id):
    # ä»å‰ç«¯è·å–è¡¨åç¼€ï¼ˆsuffixï¼‰
    # session_name = request.args.get("sessionName")
    # dataset_name = request.args.get("datasetName")

    print("########è¿›å…¥get_vector##########")
    table_suffix = request.args.get("sessionName")
    print("##############table_suffix",table_suffix)



    if not table_suffix:
        return jsonify({'error': 'ç¼ºå°‘å‚æ•° tableSuffix'}), 400

    user_id = session.get("user_id")


    table_name = f"user{user_id}_history_{table_suffix}"

    try:
        # æŸ¥è¯¢è¯¥è¡¨ä¸­çš„æŒ‡å®š item
        query_sql = f"SELECT vector_retrieval_result FROM `{table_name}` WHERE id = %s"
        cursor = mysql.cursor
        cursor.execute(query_sql, (item_id,))
        result = cursor.fetchone()

        if not result:
            return jsonify({'error': f'æœªæ‰¾åˆ° ID ä¸º {item_id} çš„è®°å½•'}), 404

        # è§£æ vector_retrieval_result å­—æ®µ
        raw_retrieval = result[0]
        try:
            retrieval_chunks = json.loads(raw_retrieval) if raw_retrieval else []
        except json.JSONDecodeError:
            retrieval_chunks = [raw_retrieval]  # é JSON åˆ—è¡¨ï¼ŒåŸæ ·è¿”å›

        return jsonify({
            'id': item_id,
            'chunks': retrieval_chunks
        })

    except Exception as e:
        return jsonify({'error': f'æŸ¥è¯¢å¤±è´¥: {str(e)}'}), 500


@app.route('/get-graph/<item_id>', methods=['GET'])
@login_required
def get_graph(item_id):
    user_id = session.get("user_id")
    table_suffix = request.args.get("sessionName")

    if not user_id or not table_suffix:
        return jsonify({'error': 'ç¼ºå°‘å‚æ•° tableSuffix æˆ–ç”¨æˆ·æœªç™»å½•'}), 400

    table_name = f"user{user_id}_history_{table_suffix}"

    try:
        cursor = mysql.cursor
        query_sql = f"SELECT graph_retrieval_result FROM `{table_name}` WHERE id = %s"
        cursor.execute(query_sql, (item_id,))
        result = cursor.fetchone()

        if not result:
            return jsonify({'error': f'æœªæ‰¾åˆ° ID ä¸º {item_id} çš„è®°å½•'}), 404

        # è·å– graph_retrieval_result å­—æ®µï¼ˆå¯èƒ½æ˜¯ JSON å­—ç¬¦ä¸²æˆ– listï¼‰
        raw_graph_data = result[0]

        try:
            graph_data = json.loads(raw_graph_data) if isinstance(raw_graph_data, str) else raw_graph_data
        except json.JSONDecodeError:
            return jsonify({'error': 'å›¾æ•°æ®æ ¼å¼è§£æå¤±è´¥ï¼ˆä¸æ˜¯åˆæ³• JSONï¼‰'}), 500

        # è·å–å›¾ç»“æ„
        evidence_entity, evidence_path = get_evidence(EVIDENCE_FILE_PATH, item_id)
        triples = convert_rel_to_triplets(graph_data)

        if not triples:
            return jsonify({'edges': [], 'nodes': [], 'highlighted-edge': [], 'highlighted-node': []})

        json_result = triples_to_json(triples, evidence_entity, evidence_path)
        return jsonify(json_result)

    except Exception as e:
        print(f"âŒ get-graph æŸ¥è¯¢å¤±è´¥: {e}")
        return jsonify({'error': f'æ•°æ®åº“æŸ¥è¯¢é”™è¯¯: {str(e)}'}), 500
















# --- æ£€ç´¢è¯¦æƒ… API æœ¬åœ°ç‰ˆæœ¬ï¼Œä»æ–‡ä»¶è·¯å¾„ä¸­è¯»å– ---
# @app.route('/get-vector/<item_id>', methods=['GET'])
# @login_required
# def get_vector(item_id):
#     # è·å–ä¸ item_id ç›¸å…³çš„ vector æ•°æ®
#     session_name = request.args.get("sessionName")
#     dataset_name = request.args.get("datasetName")


#     session_file = os.path.abspath(
#         os.path.join(os.path.dirname(__file__), '..', 'backend/llmragenv','chat_history', dataset_name,f"{session_name}.json")
#     )
#     filtered_data = load_and_filter_data(session_file, item_id)
#     retrieval_result = []
#     if filtered_data:
#          # ç¡®ä¿å‰ç«¯æœŸæœ›çš„ 'chunks' é”®å­˜åœ¨
#         if 'vector_retrieval_result' in filtered_data and isinstance(filtered_data['vector_retrieval_result'], list):
            
#              # ç®€å•åœ°å°† retrieve_results çš„å€¼ï¼ˆå‡è®¾æ˜¯æ–‡æœ¬åˆ—è¡¨ï¼‰è½¬æ¢ä¸º chunk å¯¹è±¡
#              for text_list in filtered_data['vector_retrieval_result']:
#                  retrieval_result.append(text_list)
        
#         # print("#######retrieval_result########",retrieval_result)
#         result = {
#             'id': item_id,
#             'chunks': retrieval_result
            
#         }

#         return jsonify(result)  # è¿”å›å¤„ç†åçš„æ•°æ®
#     else:
#         return jsonify({'error': f'Item not found or invalid ID format for vector lookup: {item_id}'}), 404

# @app.route('/get-graph/<item_id>', methods=['GET'])
# @login_required
# def get_graph(item_id):
#     session_name = request.args.get("sessionName")
#     dataset_name = request.args.get("datasetName")


#     session_file = os.path.abspath(
#         os.path.join(os.path.dirname(__file__), '..', 'backend/llmragenv','chat_history', dataset_name,f"{session_name}.json")
#     )
#     filtered_data = load_and_filter_data(session_file, item_id)
#     if filtered_data and 'graph_retrieval_result' in filtered_data:
#         evidence_entity,evidence_path = get_evidence(EVIDENCE_FILE_PATH,item_id)
#         # è½¬æ¢ retrieve_results ä¸ºä¸‰å…ƒç»„
#         triples = convert_rel_to_triplets(filtered_data["graph_retrieval_result"])
#         print("############triples###########",triples)
#         if not triples:
#              # print(f"Warning: No triples generated for item {item_id}. Returning empty graph.")
#              return jsonify({'edges': [], 'nodes': [], 'highlighted-edge': [], 'highlighted-node': []})

#         json_result = triples_to_json(triples,evidence_entity,evidence_path)
#         # print("================= GRAPH RESPONSE =================") # åŸå§‹è°ƒè¯•ä¿¡æ¯
#         # print(json.dumps(json_result, indent=2))                  # åŸå§‹è°ƒè¯•ä¿¡æ¯
#         # print("================================================") # åŸå§‹è°ƒè¯•ä¿¡æ¯
#         return jsonify(json_result)  # è¿”å›æ‰¾åˆ°çš„æ•°æ®
#     elif filtered_data is None:
#          # å¦‚æœ load_and_filter_data è¿”å› None (ID ä¸æ˜¯æ•´æ•°æˆ–æ–‡ä»¶æ‰¾ä¸åˆ°)
#         return jsonify({'error': f'Item not found or invalid ID format for graph lookup: {item_id}'}), 404
#     else:
#         # å¦‚æœæ‰¾åˆ°äº†æ•°æ®ä½†æ ¼å¼ä¸å¯¹
#         print(f"Warning: Graph data format error or missing 'retrieve_results' for item {item_id}")
#         return jsonify({'error': f'Data format error for graph item {item_id}'}), 500

# --- åˆ†æ / å»ºè®®è·¯ç”± ---
@app.route('/get_suggestions', methods=['GET'])
def adviser():
    # å‡è®¾ä¸‹é¢è¿™äº›æ–‡ä»¶è·¯å¾„æ˜¯æ­£ç¡®çš„
    rgb_graph_generation = "/home/lipz/NeutronRAG/NeutronRAG/backend/evaluator/rgb/graphrag/analysis_generation___merged.json"
    rgb_graph_retrieval = "/home/lipz/NeutronRAG/NeutronRAG/backend/evaluator/rgb/graphrag/analysis_retrieval_merged.json"
    rgb_vector_generation = "/home/lipz/NeutronRAG/NeutronRAG/backend/evaluator/rgb/vectorrag/analysis_generation___top5_2024-11-26_21-32-23.json"
    rgb_vector_retrieval = "/home/lipz/NeutronRAG/NeutronRAG/backend/evaluator/rgb/vectorrag/analysis_retrieval___top5_2024-11-26_21-32-23.json"

    try: # æ·»åŠ  try-except å—
        # å‡è®¾ statistic_error_cause å‡½æ•°å·²ç»å®šä¹‰ä¸”å¯ç”¨
        v_retrieve_error, v_lose_error, v_lose_correct = simulate.statistic_error_cause(rgb_vector_generation, rgb_vector_retrieval, "vector")
        g_retrieve_error, g_lose_error, g_lose_correct = simulate.statistic_error_cause(rgb_graph_generation, rgb_graph_retrieval, "graph")
        suggestions = {
            "vector_retrieve_error": v_retrieve_error, "vector_lose_error": v_lose_error, "vector_lose_correct": v_lose_correct,
            "graph_retrieve_error": g_retrieve_error, "graph_lose_error": g_lose_error, "graph_lose_correct": g_lose_correct,
            "advice": "è¿™é‡Œæ˜¯å¯¹ç”¨æˆ·çš„å»ºè®®" # åŸå§‹å»ºè®®æ–‡æœ¬
        }
        # print(suggestions) # åŸå§‹è°ƒè¯•ä¿¡æ¯
        return jsonify(suggestions)
    except AttributeError:
         error_msg = "Error: 'simulate' module or 'statistic_error_cause' function not found or loaded correctly."
         print(error_msg)
         return jsonify({"error": error_msg}), 500
    except Exception as e:
        error_msg = f"An error occurred while generating suggestions: {e}"
        print(error_msg)
        traceback.print_exc()
        return jsonify({"error": error_msg}), 500

@app.route('/get_accuracy', methods=['GET'])
# @login_required
def get_accuracy():
    # æ¨¡æ‹Ÿçš„å‡†ç¡®åº¦æ•°æ®ï¼Œå®é™…å¯ä»¥ä»æ¨¡å‹æˆ–æ•°æ®åº“ä¸­è·å– (åŸå§‹æ³¨é‡Š)
    # æ³¨æ„: è¿™ä¸ªæ¥å£å¯èƒ½ä¸ /api/analysis_data é‡å¤ï¼Œè€ƒè™‘æ˜¯å¦ä¿ç•™
    try: # æ·»åŠ  try-except
        # å‡è®¾ simulate æ¨¡å—å’Œç›¸åº”å‡½æ•°å¯ç”¨
        graph_gen_faithfulness, graph_gen_accuracy = simulate.statistic_graph_generation(simulate.rgb_graph_generation)
        vector_gen_precision, vector_gen_faithfulness, vector_gen_accuracy = simulate.statistic_vector_generation(simulate.rgb_vector_generation)
        data = {
            "vector_accuracy": round(vector_gen_accuracy * 100, 1),
            "graph_accuracy": round(graph_gen_accuracy * 100, 1),
            "hybrid_accuracy": 85 # åŸå§‹å ä½ç¬¦
        }
        return jsonify(data)
    except AttributeError:
        error_msg = "Error: 'simulate' module or statistics functions not found or loaded correctly."
        print(error_msg)
        return jsonify({"error": error_msg}), 500
    except Exception as e:
        error_msg = f"An error occurred while getting accuracy: {e}"
        print(error_msg)
        traceback.print_exc()
        return jsonify({"error": error_msg}), 500

@app.route('/api/analysis_data', methods=['GET'])
# @login_required
def get_analysis_data():
    try: # æ·»åŠ  try-except
        # å‡è®¾ simulate æ¨¡å—å’Œç›¸åº”æ–‡ä»¶/å‡½æ•°å¯ç”¨
        graph_gen_faithfulness, graph_gen_accuracy = simulate.statistic_graph_generation(simulate.rgb_graph_generation)
        graph_ret_recall, graph_ret_relevance = simulate.statistic_graph_retrieval(simulate.rgb_graph_retrieval)
        vector_gen_precision, vector_gen_faithfulness, vector_gen_accuracy = simulate.statistic_vector_generation(simulate.rgb_vector_generation)
        vector_ret_precision, vector_ret_relevance, vector_ret_recall = simulate.statistic_vector_retrieval(simulate.rgb_vector_retrieval)
        hybrid_precision, hybrid_faithfulness, hybrid_accuracy, hybrid_relevance, hybrid_recall = simulate.statistic_hybrid_generation(simulate.rgb_vector_retrieval)

        # ä¸´æ—¶ç»Ÿè®¡
        error_stats_vectorrag = {'None Result': 37.7, 'Lack Information': 14.2, 'Noisy': 7.1, 'Other': 41.0}
        error_stats_graphrag = {'None Result': 69.4, 'Lack Information': 8.3, 'Noisy': 5.6, 'Other': 16.7}
        error_stats_hybridrag = {'None Result': 36.8, 'Lack Information': 9.1, 'Noisy': 9.1, 'Other': 45.0}

        # ä¸´æ—¶ hybridrag ç»Ÿè®¡
        eval_metrics_vectorrag = {'precision': vector_ret_precision, 'relevance': vector_ret_relevance, 'recall': vector_ret_recall, 'faithfulness': vector_gen_faithfulness, 'accuracy': vector_gen_accuracy}
        eval_metrics_graphrag = {'precision': graph_ret_relevance, 'relevance': graph_ret_relevance, 'recall': graph_ret_recall, 'faithfulness': graph_gen_faithfulness, 'accuracy': graph_gen_accuracy}
        eval_metrics_hybridrag = {'precision': hybrid_precision, 'relevance': hybrid_relevance, 'recall': hybrid_recall, 'faithfulness': hybrid_faithfulness, 'accuracy': hybrid_accuracy}
        
        # ä¸´æ—¶ hybridrag ç»Ÿè®¡
        analysis_data = {
            "accuracy": { "graphrag": round(graph_gen_accuracy * 100, 1), "vectorrag": round(vector_gen_accuracy * 100, 1), "hybridrag": round(hybrid_accuracy * 100, 1) },
            "errorStatistics": { "vectorrag": error_stats_vectorrag, "graphrag": error_stats_graphrag, "hybridrag": error_stats_hybridrag },
            "evaluationMetrics": { "vectorrag": eval_metrics_vectorrag, "graphrag": eval_metrics_graphrag, "hybridrag": eval_metrics_hybridrag }
        }
        # print(analysis_data) # åŸå§‹è°ƒè¯•ä¿¡æ¯
        return jsonify(analysis_data)
    except AttributeError:
         error_msg = "Error: 'simulate' module or statistics functions/files not found or loaded correctly."
         print(error_msg)
         return jsonify({"error": error_msg}), 500
    except Exception as e:
        error_msg = f"An error occurred while generating analysis data: {e}"
        print(error_msg)
        traceback.print_exc()
        return jsonify({"error": error_msg}), 500

# --- åˆ›å»ºæ•°æ®åº“è¡¨çš„å‘½ä»¤ ---
@app.cli.command("create-db")
def create_db_command():
    """æ ¹æ® models.py åˆ›å»ºæ•°æ®åº“è¡¨ã€‚"""
    if DB_INIT_SUCCESS: # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦æˆåŠŸåˆå§‹åŒ–
        with app.app_context():
            try: 
                db.create_all()
                print("æ•°æ®åº“è¡¨åˆ›å»ºæˆåŠŸï¼ˆæˆ–å·²å­˜åœ¨ï¼‰ã€‚")
            except Exception as e: print(f"é”™è¯¯ï¼šåˆ›å»ºæ•°æ®åº“è¡¨æ—¶å‡ºé”™ï¼š{e}"); traceback.print_exc()
    else: print("é”™è¯¯ï¼šæ— æ³•åˆ›å»ºè¡¨ï¼Œæ•°æ®åº“åˆå§‹åŒ–å¤±è´¥æˆ–æœªé…ç½®ã€‚")

# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == '__main__':
    ui_port = int(os.environ.get('FLASK_PORT', 5000))
    print(f" * å¯åŠ¨ Flask åº”ç”¨äº http://0.0.0.0:{ui_port}")
    # (çœç•¥å¯åŠ¨ä¿¡æ¯æ‰“å° - åŒå‰)
    if not RAG_CORE_LOADED: print(" * è­¦å‘Šï¼šRAG æ ¸å¿ƒæœªåŠ è½½ã€‚")
    if not DB_INIT_SUCCESS: print(" * é”™è¯¯ï¼šæ•°æ®åº“æœªæ­£ç¡®é…ç½®æˆ–åˆå§‹åŒ–å¤±è´¥ï¼ŒåŠŸèƒ½å—é™ã€‚")
    print("#################################")
    app.run(host='0.0.0.0', port=ui_port, debug=False, threaded=True)